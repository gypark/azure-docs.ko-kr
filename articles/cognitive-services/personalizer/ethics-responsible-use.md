---
title: 윤리 및 사용 책임 - Personalizer
titleSuffix: Azure Cognitive Services
description: 이러한 지침은 회사와 서비스에서 신뢰를 구축하는 데 도움이 되는 방식으로 맞춤 설정을 구현하기 위한 것입니다. 잠시 여유를 갖고 맞춤 설정이 사람들의 삶에 미치는 영향에 대해 연구하고, 알아보고, 깊이 생각해 보세요. 의심스러우면 지침을 확인해 보세요.
author: edjez
manager: nitinme
ms.service: cognitive-services
ms.subservice: personalizer
ms.topic: overview
ms.date: 05/07/2019
ms.author: edjez
ms.openlocfilehash: 437dc1fba2502602109483aa9d6f25b4265af26f
ms.sourcegitcommit: 509e1583c3a3dde34c8090d2149d255cb92fe991
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 05/27/2019
ms.locfileid: "66239881"
---
# <a name="guidelines-for-responsible-implementation-of-personalizer"></a>책임 있는 Personalizer 구현 지침

개인과 사회에서 AI의 잠재력을 최대한 실현하려면 AI를 애플리케이션에 추가하는 실체와 AI를 통해 빌드된 애플리케이션 사용자의 신뢰를 받을 수 있는 방식으로 구현을 설계해야 합니다. 이러한 지침은 회사와 서비스에서 신뢰를 구축하는 데 도움이 되는 방식으로 Personalizer를 구현하기 위한 것입니다. 잠시 여유를 갖고 맞춤 설정이 사람들의 삶에 미치는 영향에 대해 연구하고, 알아보고, 깊이 생각해 보세요. 의심스러우면 지침을 확인해 보세요.

이러한 지침은 법률 자문을 위한 것이 아니며, 이 영역 및 자신의 분야에서 빠르게 진행되는 법률 개발 사항을 애플리케이션에서 준수하는지를 별도로 확인해야 합니다.

또한 Personalizer를 사용하여 애플리케이션을 설계하는 경우 윤리, 개인 정보 보호, 보안, 안전성, 포괄성, 투명성 및 책임을 포함하여 데이터 중심 AI 시스템을 개발할 때 이행해야 하는 광범위한 책임을 고려해야 합니다. 이러한 주제에 대해서는 [추천 자료](#recommended-reading) 섹션에서 자세히 참조할 수 있습니다.

다음 내용은 시작을 위한 검사 목록으로 사용하여 자신의 시나리오에 맞게 사용자 지정하고 구체화할 수 있습니다. 이 문서에는 두 가지 주요 섹션이 있습니다. 첫 번째 섹션에서는 Personalizer에 대한 시나리오, 기능 및 보상을 선택할 때 사용 책임에 대한 고려 사항을 전적으로 강조하고 있습니다. 두 번째 섹션에서는 Microsoft에서 AI 시스템을 구축할 때 고려해야 한다고 확신하는 일단의 가치를 소개하고, Personalizer를 사용함으로써 AI 시스템에 미치는 영향에 조치 가능한 제안과 위험에 대해 설명합니다. 


## <a name="your-responsibility"></a>책임

책임 있는 구현에 대한 모든 지침은 사회에서 이러한 알고리즘을 사용하는 효과와 관련하여 Personalizer를 사용하는 개발자와 회사에서 책임을 져야 한다는 사실에 기초하여 작성됩니다. 조직에서 배포하는 애플리케이션을 개발하는 경우 작업에 대한 역할과 책임 및 이로 인해 사람들에게 미치는 영향을 인식해야 합니다. 제3자가 배포할 애플리케이션을 설계하는 경우 애플리케이션의 동작에 대해 최종적인 책임이 있는 사용자와 이해를 공유하고 이러한 이해를 문서화합니다.

신뢰는 이행된 약속이라는 개념을 기반으로 합니다. 사용자, 사회 및 애플리케이션에서 작동하는 법적 프레임워크를 고려하여 관련된 명시적이고 암시적인 약속을 파악합니다.

Microsoft는 이러한 책임을 이행하는 데 도움을 주기 위해 해당 도구와 문서에서 지속적으로 노력하고 있습니다. 추가적인 도구, 제품 기능 및 문서가 Personalizer 사용과 관련된 이러한 지침을 구현하는 데 도움이 된다고 생각하는 경우 [Microsoft에 피드백을 제공해 주세요](mailto:cogsvcs-RL-feedback@microsoft.com?subject%3DPersonalizer%20Responsible%20Use%20Feedback&body%3D%5BPlease%20share%20any%20question%2C%20idea%20or%20concern%5D).


## <a name="factors-for-responsibly-implementing-personalizer"></a>책임 있는 Personalizer 구현을 위한 요인

Personalizer 구현은 사용자와 비즈니스에 중요한 가치가 될 수 있습니다. Personalizer를 책임감 있게 구현하려면 먼저 다음과 같은 경우 여기서 설명하는 지침을 고려해야 합니다.

* 맞춤 설정을 적용할 사용 사례 선택
* [보상 함수](https://github.com/Azure/personalization-rl/blob/master/docs/concepts-rewards.md) 작성
* 컨텍스트 및 맞춤 설정에 사용할 가능한 작업과 관련된 [기능](https://github.com/Azure/personalization-rl/blob/master/docs/concepts-features.md) 선택


## <a name="choosing-use-cases-for-personalizer"></a>Personalizer용 사용 사례 선택

콘텐츠와 사용자 인터페이스를 맞춤 설정하기 위해 학습하는 서비스를 사용하는 것이 유용합니다. 또한 사용자가 콘텐츠 맞춤 설정을 알지 못하는 경우를 포함하여 맞춤 설정이 실제 세계에서 부정적인 부작용을 일으키는 경우 잘못 적용될 수도 있습니다. 

부정적 부작용 또는 투명성 부족에 대한 잠재력이 높은 Personalizer 사용의 예로, 지나치게 간소화된 즉각적인 보상으로 인해 개인에게 불리한 결과를 초래할 수 있는 많은 장기적 복합 요인에 따라 "보상"이 달라지는 시나리오가 있습니다. 이러한 시나리오는 "결과적" 선택 또는 손해의 위험을 수반하는 선택으로 간주되는 경향이 있습니다. 예: 


* **재무**: 개인이 모르거나, 얻을 수 없거나, 이의를 제기할 수 없는 데이터를 기반으로 하는 위험 요인이 있는 대출, 금융 및 보험 제품에 맞춤 설정이 제공됩니다. 
* **교육**: 맞춤 설정에서 추천 사항이 편견을 전파하고 다른 옵션에 대한 사용자의 인식을 떨어뜨릴 수 있는 학교 교과 과정 및 교육 기관에 대한 순위를 지정합니다.
* **민주주의 및 시민 참여**: 여론 조성 목표가 있는 사용자에 대한 콘텐츠를 맞춤 설정하는 것은 결과적이며 조작된 것입니다.
* **제3자 보상 평가**: 사용자 자신의 동작으로 보상을 생성하는 대신 사용자에 대한 후자의 제3자 평가를 기반으로 하는 보상인 항목을 맞춤 설정합니다.
* **검색 편협성**: Personalizer의 검색 동작으로 인해 손해가 발생할 수 있는 상황입니다.

Personalizer 사용 사례를 선택하는 경우 다음을 고려합니다.

* 맞춤 설정에서 사용자를 지원하는 방법을 고려하여 설계 프로세스를 시작합니다.
* 맞춤 설정 패턴 또는 검색으로 인해 사용자에 대한 순위가 지정되지 않은 항목이 있는 경우 실제 세계의 부정적인 결과를 고려합니다.
* 자기 충족 예언 루프를 고려합니다. 이는 맞춤 설정 보상에서 모델을 학습시키고 이후에 인구 통계 그룹이 관련 콘텐츠에 액세스하지 못하도록 추가로 배제할 수 있는 경우에 발생할 수 있습니다. 예를 들어 저소득층 지역에 있는 대부분의 사람들은 프리미엄 보험 상품의 혜택을 받지 못하고 있으며, 느리지만 이웃에 있는 어느 누구도 해당 상품을 전혀 보지 않는 경향이 있습니다.
* 나중에 Personalizer를 재현해야 하는 경우에 대비하여 모델 및 학습 정책의 복사본을 저장합니다. 이 작업은 정기적으로 또는 모델 새로 고침 주기마다 수행할 수 있습니다.
* 작업 영역에 적합한 검색 수준 및 "반향실(echo chamber)" 효과를 완화하기 위한 도구로 이를 사용하는 방법을 고려합니다.


## <a name="selecting-features-for-personalizer"></a>Personalizer 기능 선택

콘텐츠 맞춤 설정은 콘텐츠와 사용자에 대해 보유한 유용한 정보에 달려 있습니다. 일부 애플리케이션 및 산업에서는 일부 사용자 기능이 직접 또는 간접적일 수 있으며, 차별적이고 잠재적으로 불법적인 것으로 간주될 수 있습니다.

다음 기능의 영향을 고려합니다.

* **사용자 인구 통계**: 성별, 나이, 인종, 종교에 관한 기능입니다. 이러한 기능은 규정상의 이유로 특정 애플리케이션에서 허용되지 않을 수 있으며, 맞춤 설정에서 일반화와 편견을 전파할 수 있으므로 이러한 기능을 맞춤 설정하는 것이 윤리적이지 않을 수 있습니다. 이러한 편견 전파의 예로 노인 또는 성별에 기반한 대상 그룹에 표시되지 않는 엔지니어링에 대한 채용 공고가 있습니다.
* **로캘 정보**: 전 세계의 많은 지역에서 위치 정보(예: 우편 번호, 또는 인근 지역 이름)는 소득, 인종 및 종교와 높은 상관 관계가 있을 수 있습니다.
* **공정성에 대한 사용자 인식**: 애플리케이션에서 올바른 결정을 내리는 경우에도 사용자가 애플리케이션에 표시된 콘텐츠가 차별적인 기능과 관련이 있는 것으로 보이는 방식으로 변경되는 것을 인식하는 효과를 고려해야 합니다.
* **기능에서 의도하지 않은 편견**:  모집단의 하위 집합에만 영향을 주는 기능을 사용하여 도입될 수 있는 편견의 유형이 있습니다. 이미지 분석을 사용하여 그림의 항목을 추출하거나 텍스트 분석을 사용하여 텍스트의 엔터티를 검색하는 경우와 같이 기능이 알고리즘 방식으로 생성되는 경우 특별히 주의해야 합니다. 이러한 기능을 만드는 데 사용하는 서비스의 특성을 알고 있어야 합니다.

컨텍스트 및 작업을 Personalizer로 보내는 기능을 선택하는 경우 다음과 같은 모범 사례를 적용합니다.

* 일부 애플리케이션에 특정 기능을 사용하는 것에 대한 합법성과 윤리 및 순수해 보이는 기능이 원하거나 피해야 하는 다른 기능을 위한 대용품이 될 수 있는지 여부를 고려합니다.
* 알고리즘과 데이터 분석을 사용하여 사용자가 보는 옵션을 맞춤 설정하는 것이 사용자에게 투명해야 합니다.
* 확인할 사항: 이 정보를 사용하여 콘텐츠를 맞춤 설정하면 사용자가 관심을 갖고 기뻐할까요? 특정 항목을 강조 표시하거나 숨기도록 결정한 방법을 보여 주는 것이 편할까요?
* 다른 특성을 기반으로 하는 데이터 분류 또는 분할을 사용하는 대신 동작을 사용합니다. 인구 통계 정보는 역사적인 이유로 소매업체에서 일반적으로 사용되었습니다. 인구 통계학적 특성은 디지털 시대 이전에 수집하고 작동하는 것이 간단한 것처럼 보였지만, 사용자의 기본 설정 및 ID와 더 밀접하게 관련된 실제 상호작용, 상황 및 기록 데이터가 있는 경우 관련 인구 통계 정보가 얼마나 관련이 있는지에 대해 의문을 제기합니다.
* 악의적인 사용자가 기능을 '스푸핑'하지 못하도록 방지하는 방법을 고려합니다. 대량으로 악용되는 경우 특정 클래스의 사용자를 의도적으로 방해하고, 당황하게 하고, 괴롭히는 잘못된 방식으로 Personalizer를 학습시킬 수 있습니다. 
* 적절하고 실현 가능한 경우 사용자가 특정 개인 기능의 사용을 옵트인하거나 옵트아웃할 수 있도록 애플리케이션을 설계합니다. 이러한 정보는 "위치 정보", "디바이스 정보", "과거 구매 내역" 등과 같이 그룹화할 수 있습니다.


## <a name="computing-rewards-for-personalizer"></a>Personalizer에 대한 컴퓨팅 보상

Personalizer는 애플리케이션 비즈니스 논리로 제공되는 보상 점수에 따라 보상할 작업을 선택하는 기능을 향상시키려고 합니다.

잘 작성된 보상 점수는 조직의 중요 업무에 연결된 비즈니스 목표에 대한 단기 프록시 역할을 합니다.

예를 들어 클릭에서 보상하면 클릭한 내용이 주의를 산만하게 하거나 비즈니스 결과에 연결되지 않더라도 Personalizer 서비스에서 다른 모든 것을 희생하여 클릭을 시도합니다.

대조적인 예로, 뉴스 사이트는 "사용자가 콘텐츠를 읽는데 충분한 시간을 사용했나요?", "관련 기사 또는 참고 자료를 클릭했나요?"와 같이 클릭보다 더 의미 있는 것으로 연결되는 보상을 설정할 수 있습니다. Personalizer를 사용하면 더 쉽게 메트릭을 보상과 밀접하게 연결할 수 있습니다. 그러나 좋은 결과를 사용하여 단기간의 사용자 참여를 혼동하지 않도록 주의해야 합니다.

### <a name="unintended-consequences-from-reward-scores"></a>보상 점수에서 의도하지 않은 결과
보상 점수는 최선의 의도로 작성될 수 있지만, Personalizer에서 콘텐츠의 순위를 지정하는 방식에 대해 예기치 않은 결과 또는 의도하지 않은 결과를 초래할 수 있습니다. 

다음 예제를 살펴보세요.

* 시청한 비디오 길이의 비율에 대해 비디오 콘텐츠 맞춤 설정을 보상하는 경우 아마도 더 짧은 비디오의 순위를 지정하는 경향이 있습니다.
* 공유 방식 또는 콘텐츠 자체에 대한 감정 분석 없이 소셜 미디어 공유를 보상하는 경우 공격적이거나, 변조되지 않거나, 선동적인 콘텐츠의 순위로 지정될 수 있으며, 이는 많은 "참여"를 유도하는 경향이 있지만 거의 가치가 없습니다.
* 사용자가 변경할 필요가 없는 사용자 인터페이스 요소에 대한 동작을 보상하는 경우 사용자 인터페이스의 유용성 및 예측 가능성을 방해할 수 있습니다. 이 경우 단추는 경고 없이 위치 또는 목적을 놀라울 정도로 변경하여 특정 사용자 그룹에서 생산성을 유지하기가 더 어려워집니다.

다음과 같은 모범 사례를 구현합니다.

* 영향과 부작용을 이해하기 위해 다양한 보상 방법을 사용하여 시스템에서 오프라인 실험을 실행합니다.
* 보상 함수를 평가하고, 매우 순진한 사람이 어떻게 해석을 왜곡시키고 바람직하지 않은 결과에 도달하는지 스스로에게 자문합니다.


## <a name="responsible-design-considerations"></a>책임 있는 설계 고려 사항

책임 있는 AI 구현을 위한 설계 영역은 다음과 같습니다. [미래 컴퓨팅](https://news.microsoft.com/futurecomputed/)에서 이 프레임워크에 대해 자세히 알아보세요.

![미래 컴퓨팅에서의 AI 가치](media/ethics-and-responsible-use/ai-values-future-computed.png)

### <a name="accountability"></a>책임감
*AI 시스템을 설계하고 배포하는 사용자는 시스템의 작동 방법에 대해 책임을 져야 합니다*. 

* Personalizer를 구현하고, 문서화하고, 팀, 임원 및 공급업체에 전달하는 방법에 대한 내부 지침을 만듭니다.
* 보상 점수를 계산하는 방법을 정기적으로 검토하고, 오프라인 평가를 수행하여 Personalizer에 영향을 주는 기능을 확인하고, 결과를 사용하여 불필요한 기능을 제거합니다.
* 사용자에게 Personalizer의 사용 방법, 용도 및 사용 데이터를 명확하게 전달합니다.
* Personalizer에서 작동하는 데 사용하는 모델, 학습 정책 및 다른 데이터와 같은 정보와 자산을 보관하여 결과를 재현할 수 있습니다.

### <a name="transparency"></a>투명성
*AI 시스템은 이해할 수 있어야 합니다*. Personalizer를 사용하는 경우 다음과 같습니다.

* *콘텐츠를 맞춤 설정한 방법에 대한 정보를 사용자에게 제공합니다.* 예를 들어 Personalizer 결과에서 역할을 수행한 사용자와 작업의 상위 기능을 사용자와 작업의 상위 기능을 보여주는 `Why These Suggestions?`라는 레이블이 지정된 단추를 사용자에게 표시할 수 있습니다.
* 사용 약관에서 사용자와 해당 동작에 대한 정보를 사용하여 환경을 맞춤 설정한다는 것을 언급해야 합니다.

### <a name="fairness"></a>공정성
*AI 시스템은 모든 사람을 공정하게 대우해야 합니다*.

* 결과가 장기적이거나, 결과적이거나, 실제적인 손해를 수반하는 사용 사례에는 Personalizer를 사용하지 않습니다.
* 콘텐츠를 맞춤 설정하는 데 적합하지 않거나 원하지 않는 편견을 전파하는 데 도움이 될 수 있는 기능은 사용하지 않습니다. 예를 들어 비슷한 재무 상황에 있는 사람은 금융 상품에 대해 동일하게 맞춤형 추천 사항을 볼 수 있어야 합니다.
* 편집기, 알고리즘 도구 또는 사용자가 제공하는 기능에 있을 수 있는 편견을 이해합니다.

### <a name="reliability-and-safety"></a>안정성 및 안전성
*AI 시스템은 안정적이고 안전하게 수행해야 합니다*. Personalizer를 사용하는 경우 다음과 같습니다.

* *선택하지 않아야 하는 작업은 Personalizer에 제공하지 않습니다*. 예를 들어 익명 또는 미성년 사용자에 대한 추천 사항을 만드는 경우 맞춤 설정할 작업에서 부적절한 동영상을 필터링해야 합니다.
* *Personalizer 모델을 비즈니스 자산으로 관리합니다*.  Personalizer 루프를 지지하는 모델과 학습 정책을 저장하고 백업하는 빈도를 고려하고, 그렇지 않으면 중요한 비즈니스 자산으로 처리합니다. 과거의 결과를 재현하는 것은 자체 감사와 측정 향상에 중요합니다.
* *사용자로부터 피드백을 직접 받을 수 있는 채널을 제공합니다*. 적합한 대상 그룹만 적합한 콘텐츠를 볼 수 있도록 안전성 검사를 코딩하는 것 외에도, 사용자가 놀라거나 혼란스러워할 수 있는 콘텐츠를 보고할 수 있는 피드백 메커니즘을 제공합니다. 특히 콘텐츠가 사용자 또는 제3자로부터 제공된 경우 Microsoft Content Moderator 또는 추가 도구를 사용하여 콘텐츠를 검토하고 유효성을 검사하는 것이 좋습니다.
* *오프라인 평가를 자주 수행합니다*. 이렇게 하면 추세를 모니터링하고 효과를 확인할 수 있습니다.
* *악의적인 조작을 감지하고 조치를 취하는 프로세스를 설정합니다*. 기계 학습과 AI 시스템의 환경 학습 능력을 활용하여 해당 목표를 향해 결과를 변화시키는 행위자도 있습니다. Personalizer를 사용하는 것이 중요한 선택에 영향을 줄 수 있는 위치에 있으면 적절한 상황에서 인적 검토를 포함하여 이러한 종류의 공격을 탐지하고 완화할 수 있는 적절한 수단이 있어야 합니다.

### <a name="security-and-privacy"></a>보안 및 개인 정보
*AI 시스템은 안전해야 하며 개인 정보를 존중해야 합니다*. Personalizer를 사용하는 경우 다음과 같습니다.

* 지역 및 업계 규정에 따라 *수집된 데이터 및 이에 대한 사용 방법을 사용자에게 미리 알리고 사전 동의를 얻습니다*.
* *개인 정보를 보호하는 사용자 제어를 제공합니다.* 개인 정보를 저장하는 애플리케이션의 경우 다음과 같은 기능을 쉽게 찾을 수 있는 단추를 제공하는 것이 좋습니다. 
   * `Show me all you know about me`    
   * `Forget my last interaction` 
   * `Delete all you know about me`

이러한 기능은 경우에 따라 법적으로 요구할 수 있습니다. 모델을 정기적으로 다시 학습시키는 경우 삭제된 데이터의 추적이 포함되지 않도록 장단점을 고려합니다.

### <a name="inclusiveness"></a>포괄성
*광범위한 사용자의 요구 사항과 환경을 처리합니다*.
* *내게 필요한 옵션 지원 인터페이스에 대한 맞춤형 환경을 제공합니다*. 노력, 이동 및 상호 작용의 불필요한 반복을 줄이기 위해 적용되는 적절한 맞춤 설정의 효율성은 장애가 있는 사람에게 특히 유용할 수 있습니다.
* *애플리케이션 동작을 상황에 맞게 조정합니다*. 예를 들어 올바른 해석은 상황과 관련되어 있을 수 있고 하나의 크기가 모두에 맞지 않을 수 있으므로 Personalizer를 사용하여 챗봇의 의도 간 차이를 명확하게 보여 줄 수 있습니다. 


## <a name="proactive-readiness-for-increased-data-protection-and-governance"></a>향상된 데이터 보호 및 거버넌스에 대한 사전 준비

규정 컨텍스트에서 특정 변경 내용을 예측하기는 어렵지만, 일반적으로 개인 데이터의 정중한 사용을 보장하고, 알고리즘 의사 결정과 관련된 투명성과 선택 항목을 제공하는 데 있어 최소한의 법적 프레임워크를 넘어서는 것이 좋습니다.


* 개인으로부터 수집된 데이터에 대한 새로운 제한이 있을 수 있고 의사 결정에서 사용된 방법을 보여줄 필요가 있는 상황을 미리 계획하는 것을 고려합니다.
* 사용자가 소외된 취약 인구, 아동, 경제적으로 취약한 사용자 또는 알고리즘 조작으로 영향을 받기 쉬운 사용자를 포함시킬 수 있는 추가 준비를 고려합니다.
* 대상 그룹을 대상으로 하고 대상 그룹에 영향을 주는 데이터 수집 프로그램과 알고리즘이 작동하는 방법 및 입증된 전략적 오류를 방지하는 방법에 대한 광범위한 불만을 고려합니다.


## <a name="proactive-assessments-during-your-project-lifecycle"></a>프로젝트 수명 주기 동안 사전 평가

팀 구성원, 사용자 및 비즈니스 소유자가 사용 책임과 관련된 문제를 보고하는 방법을 만들고, 자신의 문제 해결에 우선 순위를 지정하고 보복을 방지하는 프로세스를 만드는 것을 고려합니다.

기술 사용의 부작용에 대해 생각하는 사람은 자신의 관점과 삶의 경험에 의해 제한됩니다. 팀, 사용자 또는 자문 위원회에 더 다양한 의견을 제출하여 사용할 수 있는 의견의 범위를 넓힙니다. 이 경우 목소리를 높여 말할 수 있도록 격려합니다. 이 영역에서 팀 지식을 더욱 확장하고 복잡하고 중요한 주제를 토론할 수 있는 기능을 추가할 수 있는 학습 및 학습 자료를 고려합니다.

사용자 환경, 보안 또는 개발과 관련된 작업과 같이 애플리케이션 수명 주기의 다른 교차 작업과 마찬가지로 사용 책임과 관련된 작업을 처리하는 것을 고려합니다. 이러한 작업과 해당 요구 사항은 나중에 생각할 수 없습니다. 사용 책임은 애플리케이션 수명 주기 전체에 걸쳐 논의하고 확인해야 합니다.
 
## <a name="questions-and-feedback"></a>질문 및 피드백

Microsoft는 이러한 책임을 이행하는 데 도움을 주기 위해 도구와 문서에서 지속적으로 노력하고 있습니다. 추가적인 도구, 제품 기능 및 문서가 Personalizer 사용과 관련된 이러한 지침을 구현하는 데 도움이 된다고 생각하는 경우 [Microsoft에 피드백을 제공해 주세요](mailto:cogsvcs-RL-feedback@microsoft.com?subject%3DPersonalizer%20Responsible%20Use%20Feedback&body%3D%5BPlease%20share%20any%20question%2C%20idea%20or%20concern%5D).

## <a name="recommended-reading"></a>추천 자료

* 2018년 1월 간행의 [미래 컴퓨팅](https://news.microsoft.com/futurecomputed/) 도서에서 발표한 AI 개발 책임에 대한 Microsoft의 6가지 원칙을 참조하세요.
* [Who Owns the Future?(누가 미래를 소유하는가?)](https://www.goodreads.com/book/show/15802693-who-owns-the-future)(Jaron Lanier, 작성자)
* [Weapons of Math Destruction(수학 파괴 무기)](https://www.goodreads.com/book/show/28186015-weapons-of-math-destruction)(Cathy O'Neil, 작성자)
* [Ethics and Data Science(데이터 과학 및 윤리)](https://www.oreilly.com/library/view/ethics-and-data/9781492043898/)(DJ Patil, Hilary Mason, Mike Loukides, 공동 작성자)
* [ACM Code of Ethics(ACM 윤리 강령)](https://www.acm.org/code-of-ethics)
* [GINA(Genetic Information Nondiscrimination Act)](https://en.wikipedia.org/wiki/Genetic_Information_Nondiscrimination_Act)
* [FATML Principles for Accountable Algorithms(알고리즘 책임에 대한 FATML 원칙)](http://www.fatml.org/resources/principles-for-accountable-algorithms)


## <a name="next-steps"></a>다음 단계

[기능: 작업 및 컨텍스트](concepts-features.md)
